{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 16:51:48.867604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-14 16:51:49.095334: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-14 16:51:50.072919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-07-14 16:51:50.073008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-07-14 16:51:50.073015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0b8ab808b64bf1aa7aa4fc132a635f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "class GLM:\n",
    "    max_token: int = 2048\n",
    "    temperature: float = 0.8\n",
    "    top_p: float = 0.9\n",
    "    tokenizer: object = None\n",
    "    model: object = None\n",
    "    history_len: int = 1024\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"GLM\"\n",
    "\n",
    "    def load_model(self, llm_device=\"gpu\", model_name_or_path=None):\n",
    "        model_config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(model_name_or_path, config=model_config, trust_remote_code=True, device='cuda:2').half()\n",
    "\n",
    "    def _call(self, prompt: str, history: List[str] = [], stop: Optional[List[str]] = None):\n",
    "        response, _ = self.model.chat(\n",
    "            self.tokenizer, prompt,\n",
    "            history=history[-self.history_len:] if self.history_len > 0 else [],\n",
    "            max_length=self.max_token, temperature=self.temperature,\n",
    "            top_p=self.top_p)\n",
    "        return response\n",
    "\n",
    "modelpath = \"/data1/dxw_data/llm/chatglm3-6b-128k\"\n",
    "sys.path.append(modelpath)\n",
    "llm = GLM()\n",
    "llm.load_model(model_name_or_path=modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   1%|          | 15/1871 [02:51<9:43:21, 18.86s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2125, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   2%|▏         | 41/1871 [07:52<5:54:47, 11.63s/it] /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2087, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   2%|▏         | 44/1871 [08:22<6:20:51, 12.51s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2259, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   3%|▎         | 61/1871 [11:03<3:51:37,  7.68s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2983, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   3%|▎         | 62/1871 [11:04<2:48:43,  5.60s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2965, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   3%|▎         | 63/1871 [11:05<2:03:46,  4.11s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3005, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   3%|▎         | 64/1871 [11:05<1:32:25,  3.07s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2992, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   3%|▎         | 65/1871 [11:06<1:10:25,  2.34s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2974, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▎         | 66/1871 [11:07<55:02,  1.83s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2958, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▎         | 68/1871 [11:08<36:40,  1.22s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2970, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▎         | 69/1871 [11:08<31:25,  1.05s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2961, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▎         | 70/1871 [11:09<27:41,  1.08it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3049, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 71/1871 [11:10<25:09,  1.19it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2955, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 72/1871 [11:10<24:15,  1.24it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2996, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 73/1871 [11:11<22:40,  1.32it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2531, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 74/1871 [11:12<20:38,  1.45it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2551, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 75/1871 [11:12<19:10,  1.56it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2544, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 76/1871 [11:13<18:18,  1.63it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2538, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 77/1871 [11:13<17:31,  1.71it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2570, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 78/1871 [11:14<17:15,  1.73it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2525, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 79/1871 [11:14<16:46,  1.78it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2553, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 80/1871 [11:15<16:29,  1.81it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2566, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   4%|▍         | 81/1871 [11:15<16:28,  1.81it/s]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2273, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   6%|▌         | 112/1871 [15:31<4:19:54,  8.87s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 6387, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   6%|▌         | 116/1871 [16:09<5:15:43, 10.79s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2050, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   8%|▊         | 144/1871 [20:00<4:28:55,  9.34s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2242, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   8%|▊         | 145/1871 [20:01<3:12:13,  6.68s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2272, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   8%|▊         | 146/1871 [20:01<2:18:33,  4.82s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2228, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:   8%|▊         | 147/1871 [20:02<1:40:59,  3.51s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2239, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  12%|█▏        | 216/1871 [29:47<7:14:29, 15.75s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3629, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  12%|█▏        | 230/1871 [32:00<4:34:48, 10.05s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2487, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  16%|█▌        | 302/1871 [42:20<3:42:29,  8.51s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5423, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  18%|█▊        | 331/1871 [46:35<2:48:15,  6.56s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2072, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  18%|█▊        | 332/1871 [46:36<2:02:00,  4.76s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2073, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  25%|██▍       | 467/1871 [1:08:04<5:53:06, 15.09s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2595, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  25%|██▌       | 468/1871 [1:08:04<4:10:53, 10.73s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2623, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  25%|██▌       | 477/1871 [1:09:25<4:53:28, 12.63s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2339, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  26%|██▌       | 490/1871 [1:11:25<3:30:38,  9.15s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2374, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  26%|██▌       | 491/1871 [1:11:26<2:30:44,  6.55s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2368, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  27%|██▋       | 500/1871 [1:12:41<2:24:45,  6.34s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2571, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  27%|██▋       | 510/1871 [1:13:42<2:37:44,  6.95s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2253, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  28%|██▊       | 516/1871 [1:14:56<3:42:27,  9.85s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 7400, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  29%|██▉       | 549/1871 [1:19:43<5:05:19, 13.86s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2048, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  29%|██▉       | 550/1871 [1:19:44<3:36:24,  9.83s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2084, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  30%|██▉       | 552/1871 [1:19:53<2:45:12,  7.52s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2301, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  32%|███▏      | 595/1871 [1:26:43<2:40:27,  7.55s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2468, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  32%|███▏      | 596/1871 [1:26:44<1:55:33,  5.44s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2481, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  32%|███▏      | 597/1871 [1:26:44<1:24:11,  3.97s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2475, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  34%|███▎      | 630/1871 [1:31:30<2:54:19,  8.43s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3062, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  34%|███▎      | 631/1871 [1:31:31<2:05:54,  6.09s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2984, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  34%|███▍      | 632/1871 [1:31:31<1:32:47,  4.49s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2977, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  34%|███▍      | 633/1871 [1:31:32<1:08:49,  3.34s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2979, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  34%|███▍      | 634/1871 [1:31:33<52:08,  2.53s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2969, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  39%|███▉      | 728/1871 [1:44:40<2:34:16,  8.10s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 7419, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  40%|███▉      | 744/1871 [1:47:16<2:27:38,  7.86s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 6007, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  40%|████      | 753/1871 [1:48:18<3:04:12,  9.89s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2552, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  43%|████▎     | 801/1871 [1:56:10<1:28:01,  4.94s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2155, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  45%|████▍     | 834/1871 [2:00:31<2:51:07,  9.90s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2500, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  45%|████▍     | 835/1871 [2:00:32<2:02:22,  7.09s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2535, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  46%|████▋     | 869/1871 [2:05:51<3:53:23, 13.98s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2875, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  46%|████▋     | 870/1871 [2:05:52<2:46:13,  9.96s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2895, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  47%|████▋     | 871/1871 [2:05:53<1:59:19,  7.16s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2878, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  47%|████▋     | 872/1871 [2:05:53<1:27:04,  5.23s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2866, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  49%|████▉     | 915/1871 [2:12:45<2:19:50,  8.78s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2779, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  56%|█████▌    | 1043/1871 [2:29:46<1:47:37,  7.80s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5210, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  57%|█████▋    | 1060/1871 [2:32:24<3:02:11, 13.48s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2071, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  57%|█████▋    | 1064/1871 [2:32:55<2:16:21, 10.14s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 6294, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  57%|█████▋    | 1065/1871 [2:32:57<1:41:07,  7.53s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 6280, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  63%|██████▎   | 1175/1871 [2:49:12<54:41,  4.72s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2286, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  63%|██████▎   | 1176/1871 [2:49:13<39:53,  3.44s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2292, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  63%|██████▎   | 1177/1871 [2:49:13<29:32,  2.55s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2281, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  67%|██████▋   | 1250/1871 [2:59:25<1:00:56,  5.89s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 7398, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  71%|███████   | 1332/1871 [3:12:22<2:26:50, 16.35s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3695, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  71%|███████   | 1333/1871 [3:12:23<1:44:41, 11.68s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 3661, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  76%|███████▋  | 1428/1871 [3:28:36<56:47,  7.69s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5883, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  77%|███████▋  | 1437/1871 [3:29:50<1:06:49,  9.24s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5632, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  77%|███████▋  | 1438/1871 [3:29:51<49:22,  6.84s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5640, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  83%|████████▎ | 1551/1871 [3:46:55<1:01:25, 11.52s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 4831, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  83%|████████▎ | 1552/1871 [3:46:56<44:46,  8.42s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 4794, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  84%|████████▍ | 1577/1871 [3:50:30<32:13,  6.58s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2888, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  85%|████████▍ | 1587/1871 [3:51:24<31:42,  6.70s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2349, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  85%|████████▍ | 1588/1871 [3:51:24<22:49,  4.84s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2346, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  85%|████████▍ | 1589/1871 [3:51:25<16:37,  3.54s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2348, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  85%|████████▍ | 1590/1871 [3:51:25<12:17,  2.62s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2364, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  86%|████████▌ | 1601/1871 [3:52:13<13:31,  3.01s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2853, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  86%|████████▌ | 1602/1871 [3:52:14<10:26,  2.33s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2175, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  86%|████████▌ | 1603/1871 [3:52:15<07:54,  1.77s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2171, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  86%|████████▌ | 1604/1871 [3:52:15<06:07,  1.38s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2187, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  88%|████████▊ | 1649/1871 [4:00:52<39:52, 10.78s/it]  /home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2168, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  90%|████████▉ | 1681/1871 [4:05:05<24:26,  7.72s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2899, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  93%|█████████▎| 1740/1871 [4:13:42<11:43,  5.37s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2652, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  93%|█████████▎| 1741/1871 [4:13:42<08:30,  3.93s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2676, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  93%|█████████▎| 1742/1871 [4:13:43<06:22,  2.97s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2668, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  93%|█████████▎| 1743/1871 [4:13:44<04:47,  2.24s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2664, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  93%|█████████▎| 1745/1871 [4:13:51<06:44,  3.21s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2290, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows:  94%|█████████▍| 1765/1871 [4:15:54<13:26,  7.61s/it]/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 2436, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Processing rows: 1872it [4:35:46,  8.84s/it]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies_with_judge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件\n",
    "file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 创建Prompt模板\n",
    "def create_prompt(incident_category, matched_summary):\n",
    "    return (\n",
    "        f\"\"\"<Incident Category>: {incident_category}\n",
    "        <Matched Summary>: {matched_summary}\n",
    "        \n",
    "        First, summarize the main events described in the <matched summary>. Then analyze the correlation between the <incident category> and the <matched summary>. If all keywords in the incident category are fully addressed in the summary, return [3.0]. If some keywords are addressed but others are not, return [2.0]. If only a few or no keywords are addressed, return [1.0]. The analysis must strictly require all keywords to be addressed to return [3.0]. ### Please remember to give a final score!!!\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        <Incident Category>: corruption, bribery, extortion and money laundering\n",
    "        <Matched Summary>: The CEO of the company was implicated in fraudulent financial activities and unethical dealings. Several top executives were also found to be involved in these schemes. The investigation is currently underway.\n",
    "        Output: The main events described in the summary are the involvement of the CEO and several top executives in fraudulent financial activities and unethical dealings, and the ongoing investigation. All keywords in the incident category are addressed in the summary. \n",
    "        ## Therefore, the final score is [3.0].\n",
    "\n",
    "\n",
    "        <Incident Category>: environmental issues, supply chain issues\n",
    "        <Matched Summary>: The company has been reported for contributing to significant environmental damage through its supply chain practices. Multiple sources have confirmed that the company's facilities are releasing harmful pollutants into nearby water sources.\n",
    "        Output: The main event described in the summary is the company's role in causing environmental damage through its supply chain practices. Some keywords in the incident category are addressed in the summary, but others are not.\n",
    "        ## Therefore, the final score is [2.0].\n",
    "\n",
    "\n",
    "        <Incident Category>: occupational health and safety issues\n",
    "        <Matched Summary>: The company reported a significant increase in quarterly profits, with revenue rising by 20% compared to the previous year.\n",
    "        Output: The main event described in the summary is the company's financial performance. None of the keywords in the incident category are addressed in the summary. \n",
    "        ## Therefore, the final score is [1.0].\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "# 设置进度文件路径\n",
    "progress_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies_with_judge.json'\n",
    "\n",
    "# 结果输出文件路径\n",
    "output_txt_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/results.txt'\n",
    "\n",
    "# 读取进度文件\n",
    "if os.path.exists(progress_file_path):\n",
    "    with open(progress_file_path, 'r') as progress_file:\n",
    "        progress = json.load(progress_file)\n",
    "else:\n",
    "    progress = {'last_processed_index': -1}\n",
    "\n",
    "# 对每一行数据进行处理\n",
    "results = []\n",
    "start_index = progress['last_processed_index'] + 1\n",
    "save_interval = 10  # 每处理10行保存一次\n",
    "counter = 0  # 计数器\n",
    "\n",
    "with open(output_txt_path, 'a', encoding='utf-8') as result_file:  # 以UTF-8编码打开结果输出文件\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\", initial=start_index):\n",
    "        if index < start_index:\n",
    "            continue\n",
    "\n",
    "        incident_category = row['incident_category']\n",
    "        matched_summary = row['matched_summary_1']\n",
    "        \n",
    "        prompt = create_prompt(incident_category, matched_summary)\n",
    "        result = llm._call(prompt)\n",
    "        result_file.write(f\"Index: {index}\\n{result}\\n\\n\")  # 写入结果到文本文件\n",
    "        \n",
    "        # 提取模型返回的结果\n",
    "        if '[3.0]' in result:\n",
    "            ll_judge = 3.0\n",
    "        elif '[2.0]' in result:\n",
    "            ll_judge = 2.0\n",
    "        elif '[1.0]' in result:\n",
    "            ll_judge = 1.0\n",
    "        else:\n",
    "            ll_judge = None  # 如果模型的返回值不在预期范围内\n",
    "        \n",
    "        results.append((index, ll_judge, result))  # 保存分析结果\n",
    "        counter += 1\n",
    "        \n",
    "        # 每处理10行保存一次结果\n",
    "        if counter >= save_interval:\n",
    "            for idx, judge, analysis in results:\n",
    "                df.at[idx, 'll_judge'] = judge\n",
    "                df.at[idx, 'll_analysis'] = analysis  # 保存分析结果\n",
    "            \n",
    "            # 保存结果到CSV文件\n",
    "            output_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies_with_judge.csv'\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            \n",
    "            # 更新进度\n",
    "            progress['last_processed_index'] = index\n",
    "            with open(progress_file_path, 'w') as progress_file:\n",
    "                json.dump(progress, progress_file)\n",
    "            \n",
    "            # 重置计数器和结果列表\n",
    "            counter = 0\n",
    "            results = []\n",
    "\n",
    "    # 处理剩余的结果\n",
    "    for idx, judge, analysis in results:\n",
    "        df.at[idx, 'll_judge'] = judge\n",
    "        df.at[idx, 'll_analysis'] = analysis  # 保存分析结果\n",
    "\n",
    "    # 保存最终结果到CSV文件\n",
    "    output_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies_with_judge.csv'\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # 更新进度文件\n",
    "    progress['last_processed_index'] = df.shape[0] - 1\n",
    "    with open(progress_file_path, 'w') as progress_file:\n",
    "        json.dump(progress, progress_file)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   4%|▍         | 25/617 [05:26<1:50:42, 11.22s/it]"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件\n",
    "file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/final_match.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 创建Prompt模板\n",
    "def create_prompt(incident_category, matched_summary):\n",
    "    return (\n",
    "        f\"\"\"<Incident Category>: {incident_category}\n",
    "        <Matched Summary>: {matched_summary}\n",
    "        \n",
    "        First, summarize the main events described in the <matched summary>. Then analyze the correlation between the <incident category> and the <matched summary>. If all keywords in the incident category are fully addressed in the summary, return [3.0]. If some keywords are addressed but others are not, return [2.0]. If only a few or no keywords are addressed, return [1.0]. The analysis must strictly require all keywords to be addressed to return [3.0]. ### Please remember to give a final score!!!\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        <Incident Category>: corruption, bribery, extortion and money laundering\n",
    "        <Matched Summary>: The CEO of the company was implicated in fraudulent financial activities and unethical dealings. Several top executives were also found to be involved in these schemes. The investigation is currently underway.\n",
    "        Output: The main events described in the summary are the involvement of the CEO and several top executives in fraudulent financial activities and unethical dealings, and the ongoing investigation. All keywords in the incident category are addressed in the summary. \n",
    "        ## Therefore, the final score is [3.0].\n",
    "\n",
    "\n",
    "        <Incident Category>: environmental issues, supply chain issues\n",
    "        <Matched Summary>: The company has been reported for contributing to significant environmental damage through its supply chain practices. Multiple sources have confirmed that the company's facilities are releasing harmful pollutants into nearby water sources.\n",
    "        Output: The main event described in the summary is the company's role in causing environmental damage through its supply chain practices. Some keywords in the incident category are addressed in the summary, but others are not.\n",
    "        ## Therefore, the final score is [2.0].\n",
    "\n",
    "\n",
    "        <Incident Category>: occupational health and safety issues\n",
    "        <Matched Summary>: The company reported a significant increase in quarterly profits, with revenue rising by 20% compared to the previous year.\n",
    "        Output: The main event described in the summary is the company's financial performance. None of the keywords in the incident category are addressed in the summary. \n",
    "        ## Therefore, the final score is [1.0].\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "# 设置进度文件路径\n",
    "progress_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/filtered_companies_with_judge.json'\n",
    "\n",
    "# 结果输出文件路径\n",
    "output_txt_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/results2.txt'\n",
    "\n",
    "# 读取进度文件\n",
    "if os.path.exists(progress_file_path):\n",
    "    with open(progress_file_path, 'r') as progress_file:\n",
    "        progress = json.load(progress_file)\n",
    "else:\n",
    "    progress = {'last_processed_index': -1}\n",
    "\n",
    "# 对每一行数据进行处理\n",
    "results = []\n",
    "start_index = progress['last_processed_index'] + 1\n",
    "save_interval = 10  # 每处理10行保存一次\n",
    "counter = 0  # 计数器\n",
    "\n",
    "with open(output_txt_path, 'a', encoding='utf-8') as result_file:  # 以UTF-8编码打开结果输出文件\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\", initial=start_index):\n",
    "        if index < start_index:\n",
    "            continue\n",
    "\n",
    "        incident_category = row['incident_category']\n",
    "        matched_summary = row['matched_summary_1']\n",
    "        \n",
    "        prompt = create_prompt(incident_category, matched_summary)\n",
    "        result = llm._call(prompt)\n",
    "        result_file.write(f\"Index: {index}\\n{result}\\n\\n\")  # 写入结果到文本文件\n",
    "        \n",
    "        # 提取模型返回的结果\n",
    "        if '[3.0]' in result:\n",
    "            ll_judge = 3.0\n",
    "        elif '[2.0]' in result:\n",
    "            ll_judge = 2.0\n",
    "        elif '[1.0]' in result:\n",
    "            ll_judge = 1.0\n",
    "        else:\n",
    "            ll_judge = None  # 如果模型的返回值不在预期范围内\n",
    "        \n",
    "        results.append((index, ll_judge, result))  # 保存分析结果\n",
    "        counter += 1\n",
    "        \n",
    "        # 每处理10行保存一次结果\n",
    "        if counter >= save_interval:\n",
    "            for idx, judge, analysis in results:\n",
    "                df.at[idx, 'll_judge'] = judge\n",
    "                df.at[idx, 'll_analysis'] = analysis  # 保存分析结果\n",
    "            \n",
    "            # 保存结果到CSV文件\n",
    "            output_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/final_match.csv'\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            \n",
    "            # 更新进度\n",
    "            progress['last_processed_index'] = index\n",
    "            with open(progress_file_path, 'w') as progress_file:\n",
    "                json.dump(progress, progress_file)\n",
    "            \n",
    "            # 重置计数器和结果列表\n",
    "            counter = 0\n",
    "            results = []\n",
    "\n",
    "    # 处理剩余的结果\n",
    "    for idx, judge, analysis in results:\n",
    "        df.at[idx, 'll_judge'] = judge\n",
    "        df.at[idx, 'll_analysis'] = analysis  # 保存分析结果\n",
    "\n",
    "    # 保存最终结果到CSV文件\n",
    "    output_file_path = '/data1/dxw_data/llm/RA/hku_ivy/esg2/llm/final_match.csv'\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # 更新进度文件\n",
    "    progress['last_processed_index'] = df.shape[0] - 1\n",
    "    with open(progress_file_path, 'w') as progress_file:\n",
    "        json.dump(progress, progress_file)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
