{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 18:40:07.970688: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 18:40:08.122434: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-22 18:40:08.803024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-06-22 18:40:08.803105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-06-22 18:40:08.803111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ebe486a7694dd1810ca40a62a9004f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.base import LLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GLM(LLM):\n",
    "    max_token: int = 2048\n",
    "    temperature: float = 0.8\n",
    "    top_p = 0.9\n",
    "    tokenizer: object = None\n",
    "    model: object = None\n",
    "    history_len: int = 1024\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"GLM\"\n",
    "            \n",
    "    def load_model(self, llm_device=\"gpu\", model_name_or_path=None):\n",
    "        model_config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(model_name_or_path, config=model_config, trust_remote_code=True, device='cuda:5').half()\n",
    "\n",
    "    def _call(self, prompt: str, history: List[str] = [], stop: Optional[List[str]] = None):\n",
    "        response, _ = self.model.chat(\n",
    "            self.tokenizer, prompt,\n",
    "            history=history[-self.history_len:] if self.history_len > 0 else [],\n",
    "            max_length=self.max_token, temperature=self.temperature,\n",
    "            top_p=self.top_p\n",
    "        )\n",
    "        return response\n",
    "\n",
    "# 设置模型路径并加载模型\n",
    "modelpath = \"/data1/dxw_data/llm/chatglm3-6b\"\n",
    "llm = GLM()\n",
    "llm.load_model(model_name_or_path=modelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LangChain链\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\"],\n",
    "    template=\"\"\"请概括以下评论的主题：{comment}，最好用几个词语概括。\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 读取Excel文件\n",
    "file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data1/cleaned_comments_dianping_hotpot.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化保存结果的Excel文件路径\n",
    "output_file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data1/cleaned_comments_with_themes_label.xlsx'\n",
    "\n",
    "# 定义起始索引\n",
    "start_index = 0  # 可以根据需要更改起始索引\n",
    "\n",
    "# 定义使用GLM模型对评论进行概括的函数\n",
    "def summarize_comment(comment, index):\n",
    "    try:\n",
    "        summary = chain.run(comment)\n",
    "        print(f\"Processed comment {index + 1}: {summary}\")\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing comment {index + 1}: {e}\")\n",
    "        return f\"Summarization error: {e}\"\n",
    "\n",
    "# 使用tqdm显示进度条，并估算剩余时间\n",
    "for i in tqdm(range(start_index, len(df)), desc=\"Processing comments\", unit=\"comment\"):\n",
    "    df.at[i, 'theme'] = summarize_comment(df.at[i, 'cleaned_comment'], i)\n",
    "    df.to_excel(output_file_path, index=False)  # 保存结果到Excel文件\n",
    "    print(f\"Saved results up to comment {i + 1} to {output_file_path}\")\n",
    "\n",
    "print(f\"Final results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据提供的评论，我将提取并概括这些评论中的主题。以下是提取的主要主题：\n",
    "\n",
    "# 1. **环境**：\n",
    "#    - 干净、整洁、舒适\n",
    "#    - 脏乱差\n",
    "#    - 气氛热闹\n",
    "#    - 风景优美\n",
    "\n",
    "# 2. **服务**：\n",
    "#    - 服务态度好、热情、友好\n",
    "#    - 服务态度差、敷衍\n",
    "#    - 服务员帮忙烤肉\n",
    "#    - 免费续菜、小菜\n",
    "\n",
    "# 3. **食物质量**：\n",
    "#    - 食物新鲜\n",
    "#    - 食物品质一般\n",
    "#    - 烤肉味道好\n",
    "#    - 分量不足\n",
    "\n",
    "# 4. **价格**：\n",
    "#    - 性价比高\n",
    "#    - 价格较高\n",
    "#    - 价格合理\n",
    "\n",
    "# 5. **顾客体验**：\n",
    "#    - 总体满意\n",
    "#    - 总体不满意\n",
    "#    - 排队等待时间长\n",
    "#    - 推荐尝试\n",
    "\n",
    "# 6. **特定菜品**：\n",
    "#    - 小菜\n",
    "#    - 烤肉\n",
    "#    - 石锅拌饭\n",
    "#    - 炒年糕\n",
    "#    - 芝士鸡蛋\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LangChain链\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\"],\n",
    "    template=\"\"\"请概括以下评论的主题：{comment}，最好用几个词语概括。\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 读取Excel文件\n",
    "file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data2/cleaned_comments_dianping_barbecue.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化保存结果的Excel文件路径\n",
    "output_file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data2/cleaned_comments_with_themes_label.xlsx'\n",
    "\n",
    "# 定义起始索引\n",
    "start_index = 0  # 可以根据需要更改起始索引\n",
    "\n",
    "# 定义使用GLM模型对评论进行概括的函数\n",
    "def summarize_comment(comment, index):\n",
    "    try:\n",
    "        summary = chain.run(comment)\n",
    "        print(f\"Processed comment {index + 1}: {summary}\")\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing comment {index + 1}: {e}\")\n",
    "        return f\"Summarization error: {e}\"\n",
    "\n",
    "# 使用tqdm显示进度条，并估算剩余时间\n",
    "for i in tqdm(range(start_index, len(df)), desc=\"Processing comments\", unit=\"comment\"):\n",
    "    df.at[i, 'theme'] = summarize_comment(df.at[i, 'cleaned_comment'], i)\n",
    "    df.to_excel(output_file_path, index=False)  # 保存结果到Excel文件\n",
    "    print(f\"Saved results up to comment {i + 1} to {output_file_path}\")\n",
    "\n",
    "print(f\"Final results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据这些评论内容，可以将其分为以下几个主题：\n",
    "\n",
    "# 1. **服务质量**\n",
    "#    - 服务态度好或差\n",
    "#    - 服务员的效率和热情\n",
    "#    - 免费小菜续加服务\n",
    "\n",
    "# 2. **环境**\n",
    "#    - 环境优美或拥挤\n",
    "#    - 干净与卫生\n",
    "#    - 烤肉店的装修和氛围\n",
    "\n",
    "# 3. **食物质量**\n",
    "#    - 食材的新鲜度和口感\n",
    "#    - 具体菜品（如烤肉、石锅拌饭、芝士玉米等）的味道评价\n",
    "#    - 份量是否足够\n",
    "\n",
    "# 4. **价格**\n",
    "#    - 性价比高或低\n",
    "#    - 价格合理性\n",
    "#    - 套餐和单点菜品的价格评价\n",
    "\n",
    "# 5. **用餐体验**\n",
    "#    - 总体满意度\n",
    "#    - 适合家庭聚餐、朋友聚会等场合\n",
    "#    - 等待时间和排队情况\n",
    "\n",
    "# 6. **推荐菜品**\n",
    "#    - 特别推荐的菜品（如雪花牛肉、烤五花肉等）\n",
    "#    - 对特定菜品的详细评价\n",
    "\n",
    "# 7. **特殊场景**\n",
    "#    - 节假日或周末用餐体验\n",
    "#    - 特定活动或团购优惠\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LangChain链\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\"],\n",
    "    template=\"\"\"请概括以下评论的主题：{comment}，最好用几个词语概括。\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 读取Excel文件\n",
    "file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data3/cleaned_comments_dianping_cake.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化保存结果的Excel文件路径\n",
    "output_file_path = '/data1/dxw_data/llm/RAG-mkt-kmeans/data3/cleaned_comments_with_themes_label.xlsx'\n",
    "\n",
    "# 定义起始索引\n",
    "start_index = 0  # 可以根据需要更改起始索引\n",
    "\n",
    "# 定义使用GLM模型对评论进行概括的函数\n",
    "def summarize_comment(comment, index):\n",
    "    try:\n",
    "        summary = chain.run(comment)\n",
    "        print(f\"Processed comment {index + 1}: {summary}\")\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing comment {index + 1}: {e}\")\n",
    "        return f\"Summarization error: {e}\"\n",
    "\n",
    "# 使用tqdm显示进度条，并估算剩余时间\n",
    "for i in tqdm(range(start_index, len(df)), desc=\"Processing comments\", unit=\"comment\"):\n",
    "    df.at[i, 'theme'] = summarize_comment(df.at[i, 'cleaned_comment'], i)\n",
    "    df.to_excel(output_file_path, index=False)  # 保存结果到Excel文件\n",
    "    print(f\"Saved results up to comment {i + 1} to {output_file_path}\")\n",
    "\n",
    "print(f\"Final results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据上述评论内容，可以将其分为以下几个主题：\n",
    "\n",
    "# 1. **食物口感和质量**\n",
    "#    - 芋泥蛋糕、爆浆巧克力等具体蛋糕的口感描述（松软、细腻、甜度适中）\n",
    "#    - 特定口味的好评（芋泥、巧克力、原味等）\n",
    "#    - 芝士、咸蛋黄等其他口味的评价\n",
    "\n",
    "# 2. **价格和性价比**\n",
    "#    - 价格高低评价\n",
    "#    - 性价比高或低的意见\n",
    "#    - 对价格合理性和是否值得购买的看法\n",
    "\n",
    "# 3. **服务质量**\n",
    "#    - 服务态度和效率的评价（店员态度、管理问题）\n",
    "#    - 排队时间和购买体验（排队时间长、等待过程）\n",
    "\n",
    "# 4. **环境**\n",
    "#    - 店内环境描述和评价\n",
    "#    - 排队环境和店铺位置\n",
    "\n",
    "# 5. **购买体验**\n",
    "#    - 排队购买经历和建议（什么时候排队比较好）\n",
    "#    - 购买过程中的推荐和不推荐意见\n",
    "#    - 特定时段的购买体验（下午、傍晚）\n",
    "\n",
    "# 6. **综合评价**\n",
    "#    - 整体满意度\n",
    "#    - 推荐与否（是否值得一试、推荐给其他人）\n",
    "\n",
    "# 7. **特定体验和情感**\n",
    "#    - 个人情感和回忆（童年回忆、特别体验）\n",
    "#    - 特殊场景的体验（雨天、周末、节假日）\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
