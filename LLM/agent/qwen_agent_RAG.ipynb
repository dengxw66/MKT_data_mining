{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9d84855710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "from pydantic import BaseModel\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 09:23:31.295774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 09:23:31.418476: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 09:23:31.998410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-06-15 09:23:31.998490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2024-06-15 09:23:31.998496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dc75d104a84d10b6ad4e0660d7880b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class QwenRunnable(LLM, BaseModel):\n",
    "    model: Any\n",
    "    tokenizer: Any\n",
    "    device: str = \"cuda:0\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        response, _ = self.model.chat(self.tokenizer, query=prompt, history=None)\n",
    "        return response\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"qwen\"\n",
    "\n",
    "class Qwen:\n",
    "    def __init__(self, model_path: str, device: str = \"cuda:0\"):\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.retriever = None\n",
    "        self.llm_runnable = None\n",
    "\n",
    "    def load_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.model_path, trust_remote_code=True)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.model.generation_config = GenerationConfig.from_pretrained(self.model_path, trust_remote_code=True)\n",
    "        self.llm_runnable = QwenRunnable(model=self.model, tokenizer=self.tokenizer, device=self.device)\n",
    "\n",
    "    def load_retriever(self, doc_path: str, embedding_model_path: str, embedding_device: str = \"cuda:0\"):\n",
    "        # Load documents\n",
    "        loader = TextLoader(doc_path, encoding=\"utf-8\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Create the embedding function\n",
    "        model_kwargs = {'device': embedding_device}\n",
    "        embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_path, model_kwargs=model_kwargs)\n",
    "\n",
    "        # Load into Chroma\n",
    "        db = Chroma.from_documents(docs, embedding_function)\n",
    "        self.retriever = db.as_retriever()\n",
    "\n",
    "    def generate_response(self, prompt: str, history: list = None):\n",
    "        response, history = self.model.chat(self.tokenizer, query=prompt, history=history)\n",
    "        return response\n",
    "\n",
    "    def generate_image_caption(self, image_path: str, prompt: str):\n",
    "        query = self.tokenizer.from_list_format([\n",
    "            {'image': image_path}, \n",
    "            {'text': prompt}\n",
    "        ])\n",
    "        response, history = self.model.chat(self.tokenizer, query=query, history=None)\n",
    "        return response\n",
    "\n",
    "    def run_qa(self, query: str):\n",
    "        qa = RetrievalQA.from_chain_type(llm=self.llm_runnable, chain_type=\"stuff\", retriever=self.retriever)\n",
    "        return qa.run(query)\n",
    "\n",
    "    def run_chain(self, env: str):\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"env\"],\n",
    "            template=\"对于产品{env}，有哪些评价?\",\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm_runnable, prompt=prompt)\n",
    "        return chain.run(env)\n",
    "\n",
    "# Path to the model directory\n",
    "model_path = \"/data1/dxw_data/llm/Qwen-VL-Chat\"\n",
    "# Specify the device (e.g., 'cuda:0', 'cuda:1')\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Instantiate and load the model\n",
    "qwen_model = Qwen(model_path, device)\n",
    "qwen_model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 119, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 229, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 152, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 115, which is longer than the specified 100\n",
      "Created a chunk of size 182, which is longer than the specified 100\n",
      "Created a chunk of size 104, which is longer than the specified 100\n",
      "Created a chunk of size 185, which is longer than the specified 100\n",
      "Created a chunk of size 199, which is longer than the specified 100\n",
      "Created a chunk of size 104, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "No sentence-transformers model found with name /data1/dxw_data/llm/text2vec-large-chinese. Creating a new one with MEAN pooling.\n",
      "/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据文档内容，这些用户评论可以分为以下主题：\n",
      "1. 老婆饼：有用户表示御蝶坊的老婆饼是最有名的，味道好，但是也有用户表示购买的老婆饼口味发酸，怀疑是之前未卖完的重新装袋打日期卖的。\n",
      "2. 价格：有用户表示御蝶坊的价格越来越贵。\n",
      "3. 面包：有用户表示御蝶坊的面包新鲜，用料实料，是孩子放心的早餐选择，也推荐购买。\n",
      "4. 蛋挞：有用户表示御蝶坊的蛋挞好吃，特别是海盐蛋糕和肉松小贝，但是也有用户表示蛋挞容易腻。\n",
      "5. 服务：有用户表示御蝶坊的服务好，环境干净，服务热情。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作为一个AI语言模型，我无法直接获取御蝶坊老婆饼的评价，因为御蝶坊是一家位于台湾的食品公司，而我无法获取台湾以外的实时信息。不过，我可以告诉你，老婆饼是一种传统的中国糕点，通常由糯米粉、糖、花生和芝麻等材料制成。这种糕点在中国非常受欢迎，因为它们口感酥脆，味道甜美。如果你有机会尝试御蝶坊的老婆饼，你可以根据自己的口味来评价它们。\n",
      "This is a beautiful, pastel-colored outfit! The pink skirt is the perfect length and material for summer. I love how it flows when I walk. The top is a nice fitted t-shirt that shows off my figure. The color is so pretty against my skin. I finished the look with some cute accessories, including a simple purse and some trendy slides. I feel so confident and put-together in this whole outfit.\n"
     ]
    }
   ],
   "source": [
    "# Load the retriever\n",
    "doc_path = \"/data1/dxw_data/llm/mkt_llm/starbuck/starbuck_comments_1.txt\"\n",
    "embedding_model_path = \"/data1/dxw_data/llm/text2vec-large-chinese\"\n",
    "qwen_model.load_retriever(doc_path, embedding_model_path, embedding_device='cuda:6')\n",
    "\n",
    "# Example QA usage\n",
    "query = \"根据文档内容,请说明有哪些这些用户评论分为哪些主题\"\n",
    "qa_response = qwen_model.run_qa(query)\n",
    "print(qa_response)\n",
    "\n",
    "# Example Chain usage\n",
    "chain_response = qwen_model.run_chain(\"御蝶坊的老婆饼\")\n",
    "print(chain_response)\n",
    "\n",
    "# Example Image Captioning usage\n",
    "image_folder = \"/data1/dxw_data/llm/mkt-englishwords/data\"\n",
    "image_index = 0  # Change this to the actual image index\n",
    "image_path = f\"{image_folder}/{image_index}.png\"\n",
    "caption_prompt = \"Generate some descriptions of the clothes in this image, following the social media style of tone\"\n",
    "caption_response = qwen_model.generate_image_caption(image_path, caption_prompt)\n",
    "print(caption_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
