{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用具体的数值做label，小数点后6位，最后回归拟合的也是msr等值-离散程度，不是准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "\n",
    "# 定义文件路径\n",
    "rawdata_path = \"/data1/dxw_data/llm/redbook_final/script_next/rawdata_20%.csv\"\n",
    "\n",
    "# 读取CSV文件\n",
    "rawdata = pd.read_csv(rawdata_path)\n",
    "\n",
    "# 将日期列转换为标准格式\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return parser.parse(date_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "rawdata['post_date'] = rawdata['post_date'].apply(parse_date)\n",
    "\n",
    "# 过滤掉无效的日期\n",
    "rawdata = rawdata.dropna(subset=['post_date'])\n",
    "\n",
    "# 输出数据格式检查\n",
    "print(rawdata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  poster_id                   post_id  nums_category_img  \\\n",
      "0  5a5e0afb11be1017b83be966  6612057b000000001a00ce44                  9   \n",
      "1  5e60e721000000000100771f  6629f7cb0000000004018e7f                  6   \n",
      "2  5bd97a789333970001407645  657da21b0000000007009a23                  9   \n",
      "3  617fb2900000000010007cda  64b9548c000000001201f3f4                  8   \n",
      "4  5f0e7aeb000000000101d59e  64970df600000000130348ee                  4   \n",
      "\n",
      "  post_date post_like post_collect  count   total  proportion  \n",
      "0     04-07       188           55  274.0  3936.0    0.069614  \n",
      "1     04-25        24           10  248.0  3936.0    0.063008  \n",
      "2     12-16       667          348  230.0  2875.0    0.080000  \n",
      "3     07-21       211           20   84.0  1905.0    0.044094  \n",
      "4     06-24      1167          695  114.0  1662.0    0.068592  \n"
     ]
    }
   ],
   "source": [
    "# 定义文件路径\n",
    "after2monthdata_path = \"/data1/dxw_data/llm/redbook_final/script_next/after2monthdata_20%.csv\"\n",
    "\n",
    "# 读取CSV文件\n",
    "after2monthdata = pd.read_csv(after2monthdata_path)\n",
    "\n",
    "# 输出数据格式检查\n",
    "print(after2monthdata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 定义文件路径\n",
    "image_dir = \"/data1/dxw_data/llm/redbook_final/script_next/data_img_20%\"\n",
    "\n",
    "# 获取图像文件列表\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "\n",
    "# 示例读取图像\n",
    "for image_file in image_files[:5]:  # 仅显示前5个示例\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割训练集和测试集\n",
    "train_rawdata = rawdata[(rawdata['post_date'].dt.month >= 1) & (rawdata['post_date'].dt.month <= 9)]\n",
    "test_rawdata = rawdata[(rawdata['post_date'].dt.month >= 10) & (rawdata['post_date'].dt.month <= 12)]\n",
    "\n",
    "train_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(train_rawdata['post_id'])]\n",
    "test_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(test_rawdata['post_id'])]\n",
    "\n",
    "# 保存新的训练集和测试集CSV文件\n",
    "train_rawdata_path = os.path.join(\"/data1/dxw_data/llm/redbook_final/script_next\", \"train_rawdata.csv\")\n",
    "test_rawdata_path = os.path.join(\"/data1/dxw_data/llm/redbook_final/script_next\", \"test_rawdata.csv\")\n",
    "train_rawdata.to_csv(train_rawdata_path, index=False)\n",
    "test_rawdata.to_csv(test_rawdata_path, index=False)\n",
    "\n",
    "train_after2monthdata_path = os.path.join(\"/data1/dxw_data/llm/redbook_final/script_next\", \"train_after2monthdata.csv\")\n",
    "test_after2monthdata_path = os.path.join(\"/data1/dxw_data/llm/redbook_final/script_next\", \"test_after2monthdata.csv\")\n",
    "train_after2monthdata.to_csv(train_after2monthdata_path, index=False)\n",
    "test_after2monthdata.to_csv(test_after2monthdata_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 1733/1733 [01:38<00:00, 17.59it/s]\n",
      "Processing data: 100%|██████████| 401/401 [00:23<00:00, 17.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件路径\n",
    "data_dir = \"/data1/dxw_data/llm/redbook_final/script_next/\"\n",
    "rawdata_path = os.path.join(data_dir, \"rawdata_20%.csv\")\n",
    "after2monthdata_path = os.path.join(data_dir, \"after2monthdata_20%.csv\")\n",
    "image_dir = os.path.join(data_dir, \"data_img_20%\")\n",
    "\n",
    "# 读取CSV文件\n",
    "rawdata = pd.read_csv(rawdata_path)\n",
    "after2monthdata = pd.read_csv(after2monthdata_path)\n",
    "\n",
    "# 将日期列转换为标准格式\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return parser.parse(date_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "rawdata['post_date'] = rawdata['post_date'].apply(parse_date)\n",
    "rawdata = rawdata.dropna(subset=['post_date'])\n",
    "\n",
    "# 分割训练集和测试集\n",
    "train_rawdata = rawdata[(rawdata['post_date'].dt.month >= 1) & (rawdata['post_date'].dt.month <= 9)]\n",
    "test_rawdata = rawdata[(rawdata['post_date'].dt.month >= 10) & (rawdata['post_date'].dt.month <= 12)]\n",
    "\n",
    "train_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(train_rawdata['post_id'])]\n",
    "test_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(test_rawdata['post_id'])]\n",
    "\n",
    "# 只使用1/10的数据\n",
    "def get_subset_indices(data, fraction=0.05):\n",
    "    data_size = len(data)\n",
    "    indices = list(range(data_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(fraction * data_size))\n",
    "    return indices[:split]\n",
    "\n",
    "train_indices = get_subset_indices(train_rawdata)\n",
    "test_indices = get_subset_indices(test_rawdata)\n",
    "\n",
    "train_rawdata = train_rawdata.iloc[train_indices]\n",
    "test_rawdata = test_rawdata.iloc[test_indices]\n",
    "\n",
    "train_after2monthdata = train_after2monthdata[train_after2monthdata['post_id'].isin(train_rawdata['post_id'])]\n",
    "test_after2monthdata = test_after2monthdata[test_after2monthdata['post_id'].isin(test_rawdata['post_id'])]\n",
    "\n",
    "# 自定义数据集类\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, rawdata, after2monthdata, image_dir, transform=None, max_images=1):\n",
    "        self.rawdata = rawdata\n",
    "        self.after2monthdata = after2monthdata\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.max_images = max_images\n",
    "        self.data = self._prepare_data()\n",
    "    \n",
    "    def _prepare_data(self):\n",
    "        data = []\n",
    "        for _, row in tqdm(self.rawdata.iterrows(), total=self.rawdata.shape[0], desc=\"Processing data\"):\n",
    "            poster_id = row['poster_id']\n",
    "            post_id = row['post_id']\n",
    "            image_files = [f for f in os.listdir(self.image_dir) if f\"{poster_id}_{post_id}\" in f]\n",
    "            images = []\n",
    "            for image_file in image_files[:self.max_images]:\n",
    "                image_path = os.path.join(self.image_dir, image_file)\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "            # 如果图像数量少于 max_images，进行填充\n",
    "            while len(images) < self.max_images:\n",
    "                images.append(torch.zeros((3, 224, 224)))\n",
    "            if images:\n",
    "                summary = row['summary']\n",
    "                label_data = self.after2monthdata[self.after2monthdata['post_id'] == post_id]['proportion']\n",
    "                if not label_data.empty:\n",
    "                    label = label_data.values[0]\n",
    "                    data.append((summary, images, label))\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        summary, images, label = self.data[idx]\n",
    "        return summary, torch.stack(images), torch.tensor(label)\n",
    "\n",
    "# 图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = MultimodalDataset(train_rawdata, train_after2monthdata, image_dir, transform=transform)\n",
    "test_dataset = MultimodalDataset(test_rawdata, test_after2monthdata, image_dir, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9850530214607716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.017840086336946115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.007403440600942953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.002849473270803823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.0014897868594354285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 7/7 [00:02<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0007812130788806826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 7/7 [00:03<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0005353983121624749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 7/7 [00:02<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.00022671680978549245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0001381988186039962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.00011259791374738728\n",
      "Model training completed and saved!\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imagebind import data\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load imagebind model\n",
    "imagebind_model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "imagebind_model.eval()\n",
    "imagebind_model.to(device)\n",
    "\n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, vision_embedding_dim, common_embedding_dim, num_heads):\n",
    "        super(CrossAttentionFusion, self).__init__()\n",
    "        self.text_linear = nn.Linear(text_embedding_dim, common_embedding_dim)\n",
    "        self.vision_linear = nn.Linear(vision_embedding_dim, common_embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=common_embedding_dim, nhead=num_heads), num_layers=2)\n",
    "        self.lstm = nn.LSTM(common_embedding_dim, common_embedding_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(common_embedding_dim, 1)\n",
    "    \n",
    "    def forward(self, text_embeddings, vision_embeddings):\n",
    "        text_embeddings = self.text_linear(text_embeddings)\n",
    "        vision_embeddings = self.vision_linear(vision_embeddings)\n",
    "        # Flatten embeddings to match Transformer input requirements\n",
    "        text_embeddings = text_embeddings.view(text_embeddings.size(0), -1, text_embeddings.size(-1))\n",
    "        vision_embeddings = vision_embeddings.view(vision_embeddings.size(0), -1, vision_embeddings.size(-1))\n",
    "        multimodal_embeddings = torch.cat((text_embeddings, vision_embeddings), dim=1)\n",
    "        multimodal_embeddings = self.transformer_encoder(multimodal_embeddings)\n",
    "        lstm_out, _ = self.lstm(multimodal_embeddings)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take output of the last time step\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "def get_embeddings(text_list, image_tensors):\n",
    "    inputs = {\n",
    "        ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
    "        ModalityType.VISION: image_tensors.to(device)\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = imagebind_model(inputs)\n",
    "    return embeddings\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    log_file = open(\"log.txt\", \"w\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            summaries, images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            text_embeddings = get_embeddings(summaries, images)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(text_embeddings[ModalityType.TEXT], text_embeddings[ModalityType.VISION])\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        log_file.write(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\\n')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}')\n",
    "    log_file.close()\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "text_embedding_dim = 1024\n",
    "vision_embedding_dim = 1024\n",
    "common_embedding_dim = 768\n",
    "num_heads = 8\n",
    "\n",
    "model = CrossAttentionFusion(text_embedding_dim, vision_embedding_dim, common_embedding_dim, num_heads).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(data_dir, \"multimodal_model.pth\"))\n",
    "\n",
    "print(\"Model training completed and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 2/13 [00:00<00:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or Infinity values found in input labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 5/13 [00:01<00:02,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or Infinity values found in input labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  69%|██████▉   | 9/13 [00:03<00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or Infinity values found in input labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 13/13 [00:04<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.15285163418375253\n",
      "Mean Squared Error: 0.19900107149744883\n",
      "Mean Absolute Error: 0.4453668563594581\n",
      "R2 Score: -305.49946717329817\n",
      "Model testing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Define function to test the model\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for summaries, images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Check for NaNs or Infinities in input data\n",
    "            if torch.isnan(images).any() or torch.isinf(images).any():\n",
    "                print(\"NaN or Infinity values found in input images\")\n",
    "                continue\n",
    "            if torch.isnan(labels).any() or torch.isinf(labels).any():\n",
    "                print(\"NaN or Infinity values found in input labels\")\n",
    "                continue\n",
    "\n",
    "            text_embeddings = get_embeddings(summaries, images)\n",
    "            outputs = model(text_embeddings[ModalityType.TEXT], text_embeddings[ModalityType.VISION])\n",
    "            \n",
    "            # Check for NaNs and Infinities in outputs\n",
    "            if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                print(\"NaN or Infinity values found in outputs\")\n",
    "                continue\n",
    "            \n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                print(\"NaN or Infinity values found in loss\")\n",
    "                continue\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            all_predictions.extend(outputs.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Check for NaNs and Infinities in all_predictions and all_labels\n",
    "    mask = ~np.isnan(all_predictions) & ~np.isinf(all_predictions) & ~np.isnan(all_labels) & ~np.isinf(all_labels)\n",
    "    all_predictions = all_predictions[mask]\n",
    "    all_labels = all_labels[mask]\n",
    "\n",
    "    mse = mean_squared_error(all_labels, all_predictions)\n",
    "    mae = mean_absolute_error(all_labels, all_predictions)\n",
    "    r2 = r2_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'R2 Score: {r2}')\n",
    "    \n",
    "    return avg_test_loss, mse, mae, r2\n",
    "\n",
    "# Initialize model, criterion\n",
    "model = CrossAttentionFusion(text_embedding_dim, vision_embedding_dim, common_embedding_dim, num_heads).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(data_dir, \"multimodal_model.pth\")))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Test the model\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "avg_test_loss, mse, mae, r2 = test_model(model, test_loader, criterion)\n",
    "\n",
    "print(\"Model testing completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
