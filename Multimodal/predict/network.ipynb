{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load JSON file\n",
    "with open('/data1/dxw_data/llm/redbook/captions_labeled.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Load pretrained ResNet\n",
    "resnet = resnet50(pretrained=False)\n",
    "resnet.load_state_dict(torch.load('/data1/dxw_data/llm/resnet/resnet50-19c8e357.pth'))\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove the classification layer\n",
    "resnet.eval()\n",
    "\n",
    "word2vec_path = '/data1/dxw_data/llm/word2vec/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec_model  = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[ 0.1407708   0.2051944   2.1315029  ... -0.03464926  0.05758793\n",
      "   0.04998261]\n",
      " [ 0.03572091  0.73791885  2.3801253  ... -0.01762899  0.04897704\n",
      "   0.04665799]\n",
      " [ 0.01663122  0.6184664   2.2751641  ... -0.01778995  0.06903729\n",
      "   0.05579346]\n",
      " ...\n",
      " [ 0.09745294  0.8403073   1.8254905  ... -0.04706735  0.03224621\n",
      "   0.046666  ]\n",
      " [ 0.11417428  0.752815    0.92227274 ... -0.00628855  0.05029674\n",
      "   0.010082  ]\n",
      " [ 0.29126734  0.67746425  0.8735173  ... -0.0061261   0.056993\n",
      "  -0.00525035]]\n",
      "X_test:  [[ 1.3038322e-01  3.7690082e-01  2.4440727e+00 ... -1.2686593e-02\n",
      "   7.4628919e-02  4.0783111e-02]\n",
      " [ 1.2907702e-01  7.8734642e-01  1.2004075e+00 ... -2.1322507e-02\n",
      "   7.8972891e-02 -4.7176466e-03]\n",
      " [ 2.1855718e-02  1.0589955e+00  4.7144836e-01 ... -3.2391463e-04\n",
      "   4.0346749e-02  2.8854102e-02]\n",
      " ...\n",
      " [ 9.3258291e-02  1.0867412e+00  1.0544221e+00 ... -2.8580261e-02\n",
      "   6.6824973e-02  4.8487276e-02]\n",
      " [ 2.0029029e-01  2.0941079e-01  2.2312903e+00 ...  2.4784633e-03\n",
      "   4.5201983e-02 -6.7858016e-03]\n",
      " [ 2.2675827e-02  3.7168473e-01  3.0722945e+00 ...  4.0236253e-02\n",
      "   5.6986295e-02 -3.8123499e-03]]\n",
      "y_train:  [1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0\n",
      " 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1\n",
      " 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1]\n",
      "y_test:  [0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 0\n",
      " 0 1 1 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess transforms for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet(image).squeeze().numpy()\n",
    "    return features\n",
    "\n",
    "# Function to extract text features\n",
    "def extract_text_features(caption):\n",
    "    words = caption.split()\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        if word in word2vec_model:\n",
    "            vector = word2vec_model[word]\n",
    "            word_vectors.append(vector)\n",
    "    if not word_vectors:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Prepare dataset\n",
    "image_features = []\n",
    "text_features = []\n",
    "labels = []\n",
    "\n",
    "for item in data:\n",
    "    image_path = os.path.join('/data1/dxw_data/llm/redbook/data', item['image'])\n",
    "    if os.path.exists(image_path):\n",
    "        img_feat = extract_image_features(image_path)\n",
    "        txt_feat = extract_text_features(item['caption'])\n",
    "        image_features.append(img_feat)\n",
    "        text_features.append(txt_feat)\n",
    "        labels.append(item['label'])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "image_features = np.array(image_features)\n",
    "text_features = np.array(text_features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Combine image and text features\n",
    "combined_features = np.hstack((image_features, text_features))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
    "print(\"X_train: \",X_train)\n",
    "print(\"X_test: \",X_test)\n",
    "print(\"y_train: \",y_train)\n",
    "print(\"y_test: \",y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.6809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define and train the MLP model\n",
    "mlp = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(512, 256), max_iter=500, random_state=42))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = mlp.score(X_train, y_train)\n",
    "test_accuracy = mlp.score(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
