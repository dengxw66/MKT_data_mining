{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 得到小于2s的项\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "llm_file_path = '/data1/dxw_data/llm/tiktok/accuracy/DatafromLLM.xlsx'\n",
    "ra_file_path = '/data1/dxw_data/llm/tiktok/accuracy/DatafromRA.xlsx'\n",
    "\n",
    "# Load DatafromLLM.xlsx\n",
    "llm_df = pd.read_excel(llm_file_path)\n",
    "\n",
    "# Filter rows where 'Time' is less than or equal to 2\n",
    "filtered_llm_df = llm_df[llm_df['Time'] <= 2][['UserID', 'Video']]\n",
    "\n",
    "# Save the filtered data to a new Excel file\n",
    "filtered_llm_df.to_csv('/data1/dxw_data/llm/tiktok/accuracy/FilteredDatafromLLM.csv', index=False)\n",
    "\n",
    "# Load DatafromRA.xlsx\n",
    "ra_df = pd.read_excel(ra_file_path)\n",
    "\n",
    "# Filter rows where '是否有效曝光' (Effective Exposure) is '否' (No)\n",
    "filtered_ra_df = ra_df[ra_df['是否有效曝光'] == '否'][['UserID', 'Video']]\n",
    "\n",
    "# Save the filtered data to a new Excel file\n",
    "filtered_ra_df.to_csv('/data1/dxw_data/llm/tiktok/accuracy/FilteredDatafromRA.csv', index=False)\n",
    "\n",
    "print(\"Filtered data has been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing completed and CSV files saved.\n"
     ]
    }
   ],
   "source": [
    "# 得到大于2s的项\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read DatafromRA.xlsx\n",
    "data_ra = pd.read_excel('/data1/dxw_data/llm/tiktok/accuracy/DatafromRA.xlsx')\n",
    "\n",
    "# Filter rows where \"是否有效曝光\" is \"是\"\n",
    "data_ra_valid = data_ra[data_ra['是否有效曝光'] == '是']\n",
    "\n",
    "# Group by UserID and Video, then create lists for Main Category and Sub Category\n",
    "grouped_ra = data_ra_valid.groupby(['UserID', 'Video'])\n",
    "ra_result = grouped_ra.agg({\n",
    "    'Main Category': lambda x: list(x),\n",
    "    'Sub Category': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "ra_result.columns = ['UserID', 'Video', 'Main_Category_list', 'Sub_Category_list']\n",
    "\n",
    "# Save the result to a new CSV\n",
    "ra_result.to_csv('/data1/dxw_data/llm/tiktok/accuracy/DatafromRA_Main_Categories.csv', index=False)\n",
    "\n",
    "# Read DatafromLLM.xlsx\n",
    "data_llm = pd.read_excel('/data1/dxw_data/llm/tiktok/accuracy/DatafromLLM.xlsx')\n",
    "\n",
    "# Filter rows where Time is greater than 2\n",
    "data_llm_valid = data_llm[data_llm['Time'] > 2]\n",
    "\n",
    "# Group by UserID and Video, then create a list for Topic\n",
    "grouped_llm = data_llm_valid.groupby(['UserID', 'Video'])\n",
    "llm_result = grouped_llm.agg({\n",
    "    'Topic': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "llm_result.columns = ['UserID', 'Video', 'Main_Category_list']\n",
    "\n",
    "# Save the result to a new CSV\n",
    "llm_result.to_csv('/data1/dxw_data/llm/tiktok/accuracy/DatafromLLM_Main_Categories.csv', index=False)\n",
    "\n",
    "print(\"Data processing completed and CSV files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched data has been saved to /data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_2.csv\n"
     ]
    }
   ],
   "source": [
    "# 计算准确度 小于2s\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "llm_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/FilteredDatafromLLM.csv'\n",
    "ra_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/FilteredDatafromRA.csv'\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_2.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv(llm_file_path)\n",
    "ra_df = pd.read_csv(ra_file_path)\n",
    "\n",
    "# Count occurrences of UserID, Video pairs in each file\n",
    "llm_counts = llm_df.groupby(['UserID', 'Video']).size().reset_index(name='LLM_num')\n",
    "ra_counts = ra_df.groupby(['UserID', 'Video']).size().reset_index(name='RA_num')\n",
    "\n",
    "# Merge the counts on UserID and Video, filling NaN with 0\n",
    "merged_df = pd.merge(llm_counts, ra_counts, on=['UserID', 'Video'], how='outer').fillna(0)\n",
    "\n",
    "# Convert the counts to integers (as they were initially counts)\n",
    "merged_df['LLM_num'] = merged_df['LLM_num'].astype(int)\n",
    "merged_df['RA_num'] = merged_df['RA_num'].astype(int)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Matched data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing string: ['Others', 'Life Sharing', 'Life Sharing', 'Life Sharing', nan, 'Life Sharing', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Plot Type', 'Leisure and Comedy', nan, 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Life Sharing', 'Others', 'Leisure and Comedy']\n",
      "Error parsing string: ['Leisure and Comedy', 'News and Current Events', 'News and Current Events', 'Leisure and Comedy', 'Leisure and Comedy', 'Others', nan, nan, 'Life Sharing', 'Plot Type', nan, 'Leisure and Comedy', 'Life Sharing', 'Appearance', 'Life Sharing', nan, 'Life Sharing', 'Sports', 'Life Sharing', 'News and Current Events', nan, 'Sports', 'Sports', 'Sports', 'Sports']\n",
      "Error parsing string: ['Life Sharing', 'Appearance', 'Leisure and Comedy', 'Appearance', 'Appearance', 'Leisure and Comedy', nan, 'Appearance', 'Appearance']\n",
      "Error parsing string: ['Life Sharing', 'Leisure and Comedy', 'Others', 'Leisure and Comedy', 'Appearance', 'Life Sharing', 'Life Sharing', 'Leisure and Comedy', 'Life Sharing', 'Life Sharing', 'Leisure and Comedy', nan, 'Celebrity Entertainment', 'News and Current Events', 'Leisure and Comedy']\n",
      "Results saved to /data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single.csv\n"
     ]
    }
   ],
   "source": [
    "# 大类匹配\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Define the category groups\n",
    "categories = [\n",
    "    [\"Product Guide\", \"Product Review\", \"Outfit Recommendations\"],\n",
    "    [\"Educational/Informational\", \"Popular Science\", \"Medical Health\", \"Education and Campus\", \"Workplace/Interpersonal Relationships\", \"Technology\"],\n",
    "    [\"Plot Type\", \"Movie Commentary\", \"Film/Variety Editing\", \"Short Skits\", \"Animation/Anime\"],\n",
    "    [\"Leisure and Comedy\", \"Creative Editing/Dubbing\", \"Satirical Parody\", \"Art Creation\", \"Street Interviews\", \"Landscape Photography\", \"Cute Pets\"],\n",
    "    [\"Life Sharing\", \"Food\", \"Vlog/Insights Sharing\", \"Travel\", \"Fitness and Beauty\", \"Skill Sharing\", \"Home Life\"],\n",
    "    [\"Appearance\", \"Dance\", \"Music\"],\n",
    "    [\"Advertising\", \"Local Culture and Tourism\", \"Public Service Advertising\"],\n",
    "    [\"Celebrity Entertainment\"],\n",
    "    [\"News and Current Events\", \"Social and Political News\"],\n",
    "    [\"Games\"],\n",
    "    [\"Sports\"],\n",
    "    [\"Automobiles\"],\n",
    "    [\"Finance\"],\n",
    "    [\"Others\"]\n",
    "]\n",
    "\n",
    "# Create a dictionary to map each category to its group index\n",
    "category_to_group = {category: index for index, group in enumerate(categories) for category in group}\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories.csv')\n",
    "ra_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromRA_Main_Categories.csv')\n",
    "\n",
    "# Function to map categories to their group indices\n",
    "def map_categories_to_groups(category_list, category_to_group):\n",
    "    return [category_to_group.get(cat, -1) for cat in category_list]\n",
    "\n",
    "# Preprocess the string to ensure it's a valid Python literal\n",
    "def preprocess_category_string(category_string):\n",
    "    # Remove newlines and extra spaces\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', category_string.strip())\n",
    "    # Ensure it's a list format\n",
    "    if not (cleaned_string.startswith(\"[\") and cleaned_string.endswith(\"]\")):\n",
    "        cleaned_string = f\"[{cleaned_string}]\"\n",
    "    return cleaned_string\n",
    "\n",
    "# Function to safely evaluate category strings\n",
    "def safe_eval(category_string):\n",
    "    try:\n",
    "        return ast.literal_eval(category_string)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string: {category_string}\")\n",
    "        return []\n",
    "\n",
    "# Function to calculate sequence match with the shorter list matching against the longer list\n",
    "def calculate_sequence_match(llm_list, ra_list, category_to_group):\n",
    "    llm_groups = map_categories_to_groups(llm_list, category_to_group)\n",
    "    ra_groups = map_categories_to_groups(ra_list, category_to_group)\n",
    "\n",
    "    # Determine which list is shorter\n",
    "    if len(ra_groups) <= len(llm_groups):\n",
    "        short_groups, long_groups = ra_groups, llm_groups\n",
    "    else:\n",
    "        short_groups, long_groups = llm_groups, ra_groups\n",
    "\n",
    "    # Sequence matching using the shorter list\n",
    "    sequence_num = 0\n",
    "    long_index = 0\n",
    "\n",
    "    for short_group in short_groups:\n",
    "        while long_index < len(long_groups):\n",
    "            if long_groups[long_index] == short_group:\n",
    "                sequence_num += 1\n",
    "                long_index += 1\n",
    "                break\n",
    "            long_index += 1\n",
    "\n",
    "    return sequence_num\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the rows in ra_df\n",
    "for _, ra_row in ra_df.iterrows():\n",
    "    user_id = ra_row['UserID']\n",
    "    video_id = ra_row['Video']\n",
    "\n",
    "    # Find the corresponding LLM row\n",
    "    llm_row = llm_df[(llm_df['UserID'] == user_id) & (llm_df['Video'] == video_id)]\n",
    "\n",
    "    if not llm_row.empty:\n",
    "        llm_categories = llm_row.iloc[0]['Main_Category_list']\n",
    "        ra_categories = ra_row['Main_Category_list']\n",
    "\n",
    "        # Preprocess and evaluate category strings\n",
    "        llm_list = safe_eval(preprocess_category_string(llm_categories))\n",
    "        ra_list = safe_eval(preprocess_category_string(ra_categories))\n",
    "\n",
    "        # Calculate all_num and sequence_num\n",
    "        all_num = min(len(ra_list), len(llm_list))  # Use the length of the shorter list\n",
    "        sequence_num = calculate_sequence_match(llm_list, ra_list, category_to_group)\n",
    "\n",
    "        # Append the results\n",
    "        results.append((user_id, video_id, all_num, sequence_num))\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['UserID', 'Video', 'all_num', 'sequence_num'])\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing string: ['Others', 'Life Sharing', 'Life Sharing', 'Life Sharing', nan, 'Life Sharing', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Plot Type', 'Leisure and Comedy', nan, 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Leisure and Comedy', 'Life Sharing', 'Others', 'Leisure and Comedy']\n",
      "Error parsing string: ['Leisure and Comedy', 'News and Current Events', 'News and Current Events', 'Leisure and Comedy', 'Leisure and Comedy', 'Others', nan, nan, 'Life Sharing', 'Plot Type', nan, 'Leisure and Comedy', 'Life Sharing', 'Appearance', 'Life Sharing', nan, 'Life Sharing', 'Sports', 'Life Sharing', 'News and Current Events', nan, 'Sports', 'Sports', 'Sports', 'Sports']\n",
      "Error parsing string: ['Life Sharing', 'Appearance', 'Leisure and Comedy', 'Appearance', 'Appearance', 'Leisure and Comedy', nan, 'Appearance', 'Appearance']\n",
      "Error parsing string: ['Life Sharing', 'Leisure and Comedy', 'Others', 'Leisure and Comedy', 'Appearance', 'Life Sharing', 'Life Sharing', 'Leisure and Comedy', 'Life Sharing', 'Life Sharing', 'Leisure and Comedy', nan, 'Celebrity Entertainment', 'News and Current Events', 'Leisure and Comedy']\n",
      "Results saved to /data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single2.csv\n"
     ]
    }
   ],
   "source": [
    "# 子类匹配\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories.csv')\n",
    "ra_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromRA_Main_Categories.csv')\n",
    "\n",
    "# Preprocess the string to ensure it's a valid Python literal\n",
    "def preprocess_category_string(category_string):\n",
    "    # Remove newlines and extra spaces\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', category_string.strip())\n",
    "    # Ensure it's a list format\n",
    "    if not (cleaned_string.startswith(\"[\") and cleaned_string.endswith(\"]\")):\n",
    "        cleaned_string = f\"[{cleaned_string}]\"\n",
    "    return cleaned_string\n",
    "\n",
    "# Function to safely evaluate category strings\n",
    "def safe_eval(category_string):\n",
    "    try:\n",
    "        return ast.literal_eval(category_string)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string: {category_string}\")\n",
    "        return []\n",
    "\n",
    "# Function to calculate sequence match with the shorter list matching against the longer list\n",
    "def calculate_sequence_match(llm_list, ra_list):\n",
    "    # Determine which list is shorter\n",
    "    if len(ra_list) <= len(llm_list):\n",
    "        short_list, long_list = ra_list, llm_list\n",
    "    else:\n",
    "        short_list, long_list = llm_list, ra_list\n",
    "\n",
    "    # Sequence matching using the shorter list\n",
    "    sequence_num = 0\n",
    "    long_index = 0\n",
    "\n",
    "    for short_item in short_list:\n",
    "        while long_index < len(long_list):\n",
    "            if long_list[long_index] == short_item:\n",
    "                sequence_num += 1\n",
    "                long_index += 1\n",
    "                break\n",
    "            long_index += 1\n",
    "\n",
    "    return sequence_num\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the rows in ra_df\n",
    "for _, ra_row in ra_df.iterrows():\n",
    "    user_id = ra_row['UserID']\n",
    "    video_id = ra_row['Video']\n",
    "\n",
    "    # Find the corresponding LLM row\n",
    "    llm_row = llm_df[(llm_df['UserID'] == user_id) & (llm_df['Video'] == video_id)]\n",
    "\n",
    "    if not llm_row.empty:\n",
    "        llm_categories = llm_row.iloc[0]['Main_Category_list']\n",
    "        ra_categories = ra_row['Main_Category_list']\n",
    "\n",
    "        # Preprocess and evaluate category strings\n",
    "        llm_list = safe_eval(preprocess_category_string(llm_categories))\n",
    "        ra_list = safe_eval(preprocess_category_string(ra_categories))\n",
    "\n",
    "        # Calculate all_num and sequence_num\n",
    "        all_num = min(len(ra_list), len(llm_list))  # Use the length of the shorter list\n",
    "        sequence_num = calculate_sequence_match(llm_list, ra_list)\n",
    "\n",
    "        # Append the results\n",
    "        results.append((user_id, video_id, all_num, sequence_num))\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['UserID', 'Video', 'all_num', 'sequence_num'])\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single2.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算具体准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to accuracy_results_2.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate totals for each UserID and Video combination\n",
    "user_video_totals = data.groupby(['UserID', 'Video']).agg({'LLM_num': 'sum', 'RA_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy with condition for each UserID and Video\n",
    "user_video_totals['accuracy'] = user_video_totals.apply(\n",
    "    lambda row: row['RA_num'] / row['LLM_num'] if row['LLM_num'] >= row['RA_num'] else row['LLM_num'] / row['RA_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate totals and average match rate for each UserID\n",
    "user_totals = data.groupby('UserID').agg({'LLM_num': 'sum', 'RA_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy for each UserID with condition\n",
    "user_totals['accuracy'] = user_totals.apply(\n",
    "    lambda row: row['RA_num'] / row['LLM_num'] if row['LLM_num'] >= row['RA_num'] else row['LLM_num'] / row['RA_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average match rate for each UserID\n",
    "average_match_rate = user_video_totals.groupby('UserID')['accuracy'].mean()\n",
    "\n",
    "# Write results to a text file\n",
    "output_file_path = 'accuracy_results_2.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Totals and Accuracy for Each UserID and Video Combination:\\n\")\n",
    "    f.write(user_video_totals.to_string())\n",
    "    f.write(\"\\n\\nTotals and Accuracy for Each UserID:\\n\")\n",
    "    f.write(user_totals.to_string())\n",
    "    f.write(\"\\n\\nAverage Match Rate for Each UserID:\\n\")\n",
    "    f.write(average_match_rate.to_string())\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to accuracy_results_singlematch_maincategory.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_793563/2952089787.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate totals for each UserID and Video combination\n",
    "user_video_totals = data.groupby(['UserID', 'Video']).agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy with condition for each UserID and Video\n",
    "user_video_totals['accuracy'] = user_video_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate totals and average match rate for each UserID\n",
    "user_totals = data.groupby('UserID').agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy for each UserID with condition\n",
    "user_totals['accuracy'] = user_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average match rate for each UserID\n",
    "average_match_rate = user_video_totals.groupby('UserID')['accuracy'].mean()\n",
    "\n",
    "# Write results to a text file\n",
    "output_file_path = 'accuracy_results_singlematch_maincategory.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Totals and Accuracy for Each UserID and Video Combination:\\n\")\n",
    "    f.write(user_video_totals.to_string())\n",
    "    f.write(\"\\n\\nTotals and Accuracy for Each UserID:\\n\")\n",
    "    f.write(user_totals.to_string())\n",
    "    f.write(\"\\n\\nAverage Match Rate for Each UserID:\\n\")\n",
    "    f.write(average_match_rate.to_string())\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to accuracy_results_singlematch_subcategory.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_793563/669154580.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_single2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate totals for each UserID and Video combination\n",
    "user_video_totals = data.groupby(['UserID', 'Video']).agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy with condition for each UserID and Video\n",
    "user_video_totals['accuracy'] = user_video_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate totals and average match rate for each UserID\n",
    "user_totals = data.groupby('UserID').agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy for each UserID with condition\n",
    "user_totals['accuracy'] = user_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average match rate for each UserID\n",
    "average_match_rate = user_video_totals.groupby('UserID')['accuracy'].mean()\n",
    "\n",
    "# Write results to a text file\n",
    "output_file_path = 'accuracy_results_singlematch_subcategory.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Totals and Accuracy for Each UserID and Video Combination:\\n\")\n",
    "    f.write(user_video_totals.to_string())\n",
    "    f.write(\"\\n\\nTotals and Accuracy for Each UserID:\\n\")\n",
    "    f.write(user_totals.to_string())\n",
    "    f.write(\"\\n\\nAverage Match Rate for Each UserID:\\n\")\n",
    "    f.write(average_match_rate.to_string())\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
