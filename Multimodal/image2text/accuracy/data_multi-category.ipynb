{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9698/9698 [12:27<00:00, 12.97it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions have been successfully replaced and saved to the Excel file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Read the Excel file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Load the pre-trained model\n",
    "model = SentenceTransformer('/data1/dxw_data/llm/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Step 3: Define the category groups\n",
    "categories = [\n",
    "    \"Product Guide\", \"Product Review\", \"Outfit Recommendations\",\n",
    "    \"Educational/Informational\", \"Popular Science\", \"Medical Health\", \"Education and Campus\", \"Workplace/Interpersonal Relationships\", \"Technology\",\n",
    "    \"Plot Type\", \"Movie Commentary\", \"Film/Variety Editing\", \"Short Skits\", \"Animation/Anime\",\n",
    "    \"Leisure and Comedy\", \"Creative Editing/Dubbing\", \"Satirical Parody\", \"Art Creation\", \"Street Interviews\", \"Landscape Photography\", \"Cute Pets\",\n",
    "    \"Life Sharing\", \"Food\", \"Vlog/Insights Sharing\", \"Travel\", \"Fitness and Beauty\", \"Skill Sharing\", \"Home Life\",\n",
    "    \"Appearance\", \"Dance\", \"Music\",\n",
    "    \"Advertising\", \"Local Culture and Tourism\", \"Public Service Advertising\",\n",
    "    \"Celebrity Entertainment\",\n",
    "    \"News and Current Events\", \"Social and Political News\",\n",
    "    \"Games\",\n",
    "    \"Sports\",\n",
    "    \"Automobiles\",\n",
    "    \"Finance\",\n",
    "    \"Others\"\n",
    "]\n",
    "\n",
    "# Step 4: Calculate embeddings for category keywords\n",
    "category_embeddings = model.encode(categories)\n",
    "\n",
    "# Function to find the closest category for a given description keyword\n",
    "def find_closest_category(keyword):\n",
    "    keyword_embedding = model.encode(keyword)\n",
    "    similarities = util.pytorch_cos_sim(keyword_embedding, category_embeddings)\n",
    "    closest_idx = similarities.argmax()\n",
    "    return categories[closest_idx]\n",
    "\n",
    "# Step 5: Process each description and replace keywords\n",
    "def replace_keywords(description):\n",
    "    if isinstance(description, str):\n",
    "        keywords = [kw.strip() for kw in description.split(';')]\n",
    "        replaced_keywords = [find_closest_category(kw) for kw in keywords]\n",
    "        return '; '.join(replaced_keywords)\n",
    "    return description  # Return the original value if it's not a string\n",
    "\n",
    "# Apply the replacement to each row with progress indication\n",
    "tqdm.pandas()\n",
    "df['Modified_Description'] = df['Description'].progress_apply(replace_keywords)\n",
    "\n",
    "# Step 6: Save the modified DataFrame back to the Excel file\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Descriptions have been successfully replaced and saved to the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing completed and CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read DatafromLLM.xlsx\n",
    "data_llm = pd.read_excel('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM.xlsx')\n",
    "\n",
    "# Step 1: Filter rows where Time is greater than 2\n",
    "data_llm_valid = data_llm[data_llm['Time'] > 2]\n",
    "\n",
    "# Step 2: Group by UserID and Video, then combine Modified_Description into a nested list structure\n",
    "def combine_descriptions(description_series):\n",
    "    # Split each description into a list of categories\n",
    "    lists_of_categories = [desc.split(';') for desc in description_series]\n",
    "    # Remove extra spaces from categories and return as nested list\n",
    "    return [list(map(lambda x: x.strip(), category_list)) for category_list in lists_of_categories]\n",
    "\n",
    "grouped_llm = data_llm_valid.groupby(['UserID', 'Video']).agg({\n",
    "    'Modified_Description': combine_descriptions\n",
    "}).reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "grouped_llm.columns = ['UserID', 'Video', 'Main_Category_list']\n",
    "\n",
    "# Save the result to a new CSV\n",
    "grouped_llm.to_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories_combined.csv', index=False)\n",
    "\n",
    "print(\"Data processing completed and CSV file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing string: [['Others'], ['Life Sharing'], ['Life Sharing'], ['Life Sharing'], nan, ['Life Sharing'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Plot Type'], ['Leisure and Comedy'], nan, ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Life Sharing'], ['Others'], ['Leisure and Comedy']]\n",
      "Error parsing string: [['Leisure and Comedy'], ['News and Current Events'], ['News and Current Events'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Others'], nan, nan, ['Life Sharing'], ['Plot Type'], nan, ['Leisure and Comedy'], ['Life Sharing'], ['Appearance'], ['Life Sharing'], nan, ['Life Sharing'], ['Sports'], ['Life Sharing'], ['News and Current Events'], nan, ['Sports'], ['Sports'], ['Sports'], ['Sports']]\n",
      "Error parsing string: [['Life Sharing'], ['Appearance'], ['Leisure and Comedy'], ['Appearance'], ['Appearance'], ['Leisure and Comedy'], nan, ['Appearance'], ['Appearance']]\n",
      "Error parsing string: [['Life Sharing'], ['Leisure and Comedy'], ['Others'], ['Leisure and Comedy'], ['Appearance'], ['Life Sharing'], ['Life Sharing'], ['Leisure and Comedy'], ['Life Sharing'], ['Life Sharing'], ['Leisure and Comedy'], nan, ['Celebrity Entertainment'], ['News and Current Events'], ['Leisure and Comedy']]\n",
      "Results saved to /data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# 大类匹配\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Define the category groups\n",
    "categories = [\n",
    "    [\"Product Guide\", \"Product Review\", \"Outfit Recommendations\"],\n",
    "    [\"Educational/Informational\", \"Popular Science\", \"Medical Health\", \"Education and Campus\", \"Workplace/Interpersonal Relationships\", \"Technology\"],\n",
    "    [\"Plot Type\", \"Movie Commentary\", \"Film/Variety Editing\", \"Short Skits\", \"Animation/Anime\"],\n",
    "    [\"Leisure and Comedy\", \"Creative Editing/Dubbing\", \"Satirical Parody\", \"Art Creation\", \"Street Interviews\", \"Landscape Photography\", \"Cute Pets\"],\n",
    "    [\"Life Sharing\", \"Food\", \"Vlog/Insights Sharing\", \"Travel\", \"Fitness and Beauty\", \"Skill Sharing\", \"Home Life\"],\n",
    "    [\"Appearance\", \"Dance\", \"Music\"],\n",
    "    [\"Advertising\", \"Local Culture and Tourism\", \"Public Service Advertising\"],\n",
    "    [\"Celebrity Entertainment\"],\n",
    "    [\"News and Current Events\", \"Social and Political News\"],\n",
    "    [\"Games\"],\n",
    "    [\"Sports\"],\n",
    "    [\"Automobiles\"],\n",
    "    [\"Finance\"],\n",
    "    [\"Others\"]\n",
    "]\n",
    "\n",
    "# Create a dictionary to map each category to its group index\n",
    "category_to_group = {category: index for index, group in enumerate(categories) for category in group}\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories_combined.csv')\n",
    "ra_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromRA_Main_Categoriess_combined.csv')\n",
    "\n",
    "# Function to preprocess and evaluate category strings safely\n",
    "def preprocess_and_eval(category_string):\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', category_string.strip())\n",
    "    if not (cleaned_string.startswith(\"[\") and cleaned_string.endswith(\"]\")):\n",
    "        cleaned_string = f\"[{cleaned_string}]\"\n",
    "    try:\n",
    "        return ast.literal_eval(cleaned_string)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string: {category_string}\")\n",
    "        return []\n",
    "\n",
    "# Function to map categories to their group indices\n",
    "def map_categories_to_groups(category_list, category_to_group):\n",
    "    return [category_to_group.get(cat, -1) for cat in category_list]\n",
    "\n",
    "# Function to find the maximum length of the matching subsequence\n",
    "def find_max_matching_sequence(llm_list, ra_list, category_to_group):\n",
    "    llm_groups = [map_categories_to_groups(sublist, category_to_group) for sublist in llm_list]\n",
    "    ra_groups = [map_categories_to_groups(sublist, category_to_group) for sublist in ra_list]\n",
    "\n",
    "    llm_elements = [el for sublist in llm_groups for el in sublist]\n",
    "    ra_elements = [el for sublist in ra_groups for el in sublist]\n",
    "\n",
    "    len_llm = len(llm_elements)\n",
    "    len_ra = len(ra_elements)\n",
    "\n",
    "    # Create a 2D array to store the lengths of longest common subsequence\n",
    "    dp = [[0] * (len_llm + 1) for _ in range(len_ra + 1)]\n",
    "\n",
    "    for i in range(1, len_ra + 1):\n",
    "        for j in range(1, len_llm + 1):\n",
    "            if ra_elements[i - 1] == llm_elements[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[len_ra][len_llm]\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the rows in ra_df\n",
    "for _, ra_row in ra_df.iterrows():\n",
    "    user_id = ra_row['UserID']\n",
    "    video_id = ra_row['Video']\n",
    "\n",
    "    # Find the corresponding LLM row\n",
    "    llm_row = llm_df[(llm_df['UserID'] == user_id) & (llm_df['Video'] == video_id)]\n",
    "\n",
    "    if not llm_row.empty:\n",
    "        llm_categories = llm_row.iloc[0]['Main_Category_list']\n",
    "        ra_categories = ra_row['Main_Category_list']\n",
    "\n",
    "        # Preprocess and evaluate category strings\n",
    "        llm_list = preprocess_and_eval(llm_categories)\n",
    "        ra_list = preprocess_and_eval(ra_categories)\n",
    "\n",
    "        # Calculate all_num and sequence_num\n",
    "        all_num = len(ra_list)  # Use the length of the RA list\n",
    "        sequence_num = find_max_matching_sequence(llm_list, ra_list, category_to_group)\n",
    "\n",
    "        # Append the results\n",
    "        results.append((user_id, video_id, all_num, sequence_num))\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['UserID', 'Video', 'all_num', 'sequence_num'])\n",
    "\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大类匹配\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Define the category groups\n",
    "categories = [\n",
    "    [\"Product Guide\", \"Product Review\", \"Outfit Recommendations\"],\n",
    "    [\"Educational/Informational\", \"Popular Science\", \"Medical Health\", \"Education and Campus\", \"Workplace/Interpersonal Relationships\", \"Technology\"],\n",
    "    [\"Plot Type\", \"Movie Commentary\", \"Film/Variety Editing\", \"Short Skits\", \"Animation/Anime\"],\n",
    "    [\"Leisure and Comedy\", \"Creative Editing/Dubbing\", \"Satirical Parody\", \"Art Creation\", \"Street Interviews\", \"Landscape Photography\", \"Cute Pets\"],\n",
    "    [\"Life Sharing\", \"Food\", \"Vlog/Insights Sharing\", \"Travel\", \"Fitness and Beauty\", \"Skill Sharing\", \"Home Life\"],\n",
    "    [\"Appearance\", \"Dance\", \"Music\"],\n",
    "    [\"Advertising\", \"Local Culture and Tourism\", \"Public Service Advertising\"],\n",
    "    [\"Celebrity Entertainment\"],\n",
    "    [\"News and Current Events\", \"Social and Political News\"],\n",
    "    [\"Games\"],\n",
    "    [\"Sports\"],\n",
    "    [\"Automobiles\"],\n",
    "    [\"Finance\"],\n",
    "    [\"Others\"]\n",
    "]\n",
    "\n",
    "# Create a dictionary to map each category to its group index\n",
    "category_to_group = {category: index for index, group in enumerate(categories) for category in group}\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories_combined.csv')\n",
    "ra_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromRA_Main_Categoriess_combined.csv')\n",
    "\n",
    "# Function to preprocess and evaluate category strings safely\n",
    "def preprocess_and_eval(category_string):\n",
    "    # Remove newlines and extra spaces\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', category_string.strip())\n",
    "    # Ensure it's a list format\n",
    "    if not (cleaned_string.startswith(\"[\") and cleaned_string.endswith(\"]\")):\n",
    "        cleaned_string = f\"[{cleaned_string}]\"\n",
    "    try:\n",
    "        return ast.literal_eval(cleaned_string)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string: {category_string}\")\n",
    "        return []\n",
    "\n",
    "# Function to map categories to their group indices\n",
    "def map_categories_to_groups(category_list, category_to_group):\n",
    "    return [category_to_group.get(cat, -1) for cat in category_list]\n",
    "\n",
    "# Function to calculate sequence match with the shorter list matching against the longer list\n",
    "def calculate_sequence_match(llm_list, ra_list, category_to_group):\n",
    "    llm_groups = [map_categories_to_groups(sublist, category_to_group) for sublist in llm_list]\n",
    "    ra_groups = [map_categories_to_groups(sublist, category_to_group) for sublist in ra_list]\n",
    "\n",
    "    sequence_num = 0\n",
    "\n",
    "    for ra_sublist in ra_groups:\n",
    "        ra_group = ra_sublist[0] if ra_sublist else -1\n",
    "        for llm_sublist in llm_groups:\n",
    "            if ra_group in llm_sublist:\n",
    "                sequence_num += 1\n",
    "                break\n",
    "\n",
    "    return sequence_num\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the rows in ra_df\n",
    "for _, ra_row in ra_df.iterrows():\n",
    "    user_id = ra_row['UserID']\n",
    "    video_id = ra_row['Video']\n",
    "\n",
    "    # Find the corresponding LLM row\n",
    "    llm_row = llm_df[(llm_df['UserID'] == user_id) & (llm_df['Video'] == video_id)]\n",
    "\n",
    "    if not llm_row.empty:\n",
    "        llm_categories = llm_row.iloc[0]['Main_Category_list']\n",
    "        ra_categories = ra_row['Main_Category_list']\n",
    "\n",
    "        # Preprocess and evaluate category strings\n",
    "        llm_list = preprocess_and_eval(llm_categories)\n",
    "        ra_list = preprocess_and_eval(ra_categories)\n",
    "\n",
    "        # Calculate all_num and sequence_num\n",
    "        all_num = len(ra_list)  # Use the length of the RA list\n",
    "        sequence_num = calculate_sequence_match(llm_list, ra_list, category_to_group)\n",
    "\n",
    "        # Append the results\n",
    "        results.append((user_id, video_id, all_num, sequence_num))\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['UserID', 'Video', 'all_num', 'sequence_num'])\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing string: [['Others'], ['Life Sharing'], ['Life Sharing'], ['Life Sharing'], nan, ['Life Sharing'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Plot Type'], ['Leisure and Comedy'], nan, ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Life Sharing'], ['Others'], ['Leisure and Comedy']]\n",
      "Error parsing string: [['Leisure and Comedy'], ['News and Current Events'], ['News and Current Events'], ['Leisure and Comedy'], ['Leisure and Comedy'], ['Others'], nan, nan, ['Life Sharing'], ['Plot Type'], nan, ['Leisure and Comedy'], ['Life Sharing'], ['Appearance'], ['Life Sharing'], nan, ['Life Sharing'], ['Sports'], ['Life Sharing'], ['News and Current Events'], nan, ['Sports'], ['Sports'], ['Sports'], ['Sports']]\n",
      "Error parsing string: [['Life Sharing'], ['Appearance'], ['Leisure and Comedy'], ['Appearance'], ['Appearance'], ['Leisure and Comedy'], nan, ['Appearance'], ['Appearance']]\n",
      "Error parsing string: [['Life Sharing'], ['Leisure and Comedy'], ['Others'], ['Leisure and Comedy'], ['Appearance'], ['Life Sharing'], ['Life Sharing'], ['Leisure and Comedy'], ['Life Sharing'], ['Life Sharing'], ['Leisure and Comedy'], nan, ['Celebrity Entertainment'], ['News and Current Events'], ['Leisure and Comedy']]\n",
      "Results saved to /data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Read the CSV files\n",
    "llm_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromLLM_Main_Categories_combined.csv')\n",
    "ra_df = pd.read_csv('/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/DatafromRA_Main_Categoriess_combined.csv')\n",
    "\n",
    "\n",
    "# Function to preprocess and evaluate category strings safely\n",
    "def preprocess_and_eval(category_string):\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', category_string.strip())\n",
    "    if not (cleaned_string.startswith(\"[\") and cleaned_string.endswith(\"]\")):\n",
    "        cleaned_string = f\"[{cleaned_string}]\"\n",
    "    try:\n",
    "        return ast.literal_eval(cleaned_string)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string: {category_string}\")\n",
    "        return []\n",
    "\n",
    "# Function to find the maximum length of the matching subsequence\n",
    "def find_max_matching_sequence(llm_list, ra_list):\n",
    "    llm_elements = [el for sublist in llm_list for el in sublist]\n",
    "    ra_elements = [el for sublist in ra_list for el in sublist]\n",
    "\n",
    "    len_llm = len(llm_elements)\n",
    "    len_ra = len(ra_elements)\n",
    "\n",
    "    # Create a 2D array to store the lengths of longest common subsequence\n",
    "    dp = [[0] * (len_llm + 1) for _ in range(len_ra + 1)]\n",
    "\n",
    "    for i in range(1, len_ra + 1):\n",
    "        for j in range(1, len_llm + 1):\n",
    "            if ra_elements[i - 1] == llm_elements[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[len_ra][len_llm]\n",
    "\n",
    "# Prepare a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the rows in ra_df\n",
    "for _, ra_row in ra_df.iterrows():\n",
    "    user_id = ra_row['UserID']\n",
    "    video_id = ra_row['Video']\n",
    "\n",
    "    # Find the corresponding LLM row\n",
    "    llm_row = llm_df[(llm_df['UserID'] == user_id) & (llm_df['Video'] == video_id)]\n",
    "\n",
    "    if not llm_row.empty:\n",
    "        llm_categories = llm_row.iloc[0]['Main_Category_list']\n",
    "        ra_categories = ra_row['Main_Category_list']\n",
    "\n",
    "        # Preprocess and evaluate category strings\n",
    "        llm_list = preprocess_and_eval(llm_categories)\n",
    "        ra_list = preprocess_and_eval(ra_categories)\n",
    "\n",
    "        # Calculate all_num and sequence_num\n",
    "        all_num = len(ra_list)  # Use the length of the RA list\n",
    "        sequence_num = find_max_matching_sequence(llm_list, ra_list)\n",
    "\n",
    "        # Append the results\n",
    "        results.append((user_id, video_id, all_num, sequence_num))\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['UserID', 'Video', 'all_num', 'sequence_num'])\n",
    "\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined2.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to accuracy_results_multimatch-maincategory.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_738239/3939665530.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate totals for each UserID and Video combination\n",
    "user_video_totals = data.groupby(['UserID', 'Video']).agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy with condition for each UserID and Video\n",
    "user_video_totals['accuracy'] = user_video_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate totals and average match rate for each UserID\n",
    "user_totals = data.groupby('UserID').agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy for each UserID with condition\n",
    "user_totals['accuracy'] = user_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average match rate for each UserID\n",
    "average_match_rate = user_video_totals.groupby('UserID')['accuracy'].mean()\n",
    "\n",
    "# Write results to a text file\n",
    "output_file_path = 'accuracy_results_multimatch-maincategory.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Totals and Accuracy for Each UserID and Video Combination:\\n\")\n",
    "    f.write(user_video_totals.to_string())\n",
    "    f.write(\"\\n\\nTotals and Accuracy for Each UserID:\\n\")\n",
    "    f.write(user_totals.to_string())\n",
    "    f.write(\"\\n\\nAverage Match Rate for Each UserID:\\n\")\n",
    "    f.write(average_match_rate.to_string())\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to accuracy_results_multimatch-subcategory.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_738239/1386846258.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data1/dxw_data/llm/MKT_data_mining/Multimodal/image2text/accuracy/MatchedData_CategorySequences_combined2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate totals for each UserID and Video combination\n",
    "user_video_totals = data.groupby(['UserID', 'Video']).agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy with condition for each UserID and Video\n",
    "user_video_totals['accuracy'] = user_video_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate totals and average match rate for each UserID\n",
    "user_totals = data.groupby('UserID').agg({'all_num': 'sum', 'sequence_num': 'sum'})\n",
    "\n",
    "# Calculate accuracy for each UserID with condition\n",
    "user_totals['accuracy'] = user_totals.apply(\n",
    "    lambda row: row['sequence_num'] / row['all_num'] if row['all_num'] >= row['sequence_num'] else row['all_num'] / row['sequence_num'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average match rate for each UserID\n",
    "average_match_rate = user_video_totals.groupby('UserID')['accuracy'].mean()\n",
    "\n",
    "# Write results to a text file\n",
    "output_file_path = 'accuracy_results_multimatch-subcategory.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Totals and Accuracy for Each UserID and Video Combination:\\n\")\n",
    "    f.write(user_video_totals.to_string())\n",
    "    f.write(\"\\n\\nTotals and Accuracy for Each UserID:\\n\")\n",
    "    f.write(user_totals.to_string())\n",
    "    f.write(\"\\n\\nAverage Match Rate for Each UserID:\\n\")\n",
    "    f.write(average_match_rate.to_string())\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
